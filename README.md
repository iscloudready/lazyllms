# ğŸ§§ LazyLLMs - Lightweight LLM Model Manager

[![GitHub License](https://img.shields.io/github/license/your-repo/lazyllms)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![Contributors](https://img.shields.io/github/contributors/your-repo/lazyllms)](https://github.com/your-repo/lazyllms/graphs/contributors)

---

## ğŸš€ Overview

**LazyLLMs** is a **TUI-based (Terminal UI) Model Manager**, inspired by **LazyDocker**, designed for **monitoring, managing, and interacting** with AI models, specifically **Ollama models**. With LazyLLMs, you can **view real-time system resource usage** and **control running AI models** directly from your terminal. Itâ€™s a powerful tool for developers and AI enthusiasts who want a lightweight, efficient way to manage their models without the overhead of graphical interfaces.

![LazyLLMs UI](https://raw.githubusercontent.com/iscloudready/lazyllms/refs/heads/main/Images/home.png)

### ğŸ”¹ Key Highlights:
- ğŸ”¹ **Real-Time Monitoring**: View live stats of running AI models including their performance and system resource usage.
- ğŸ”¹ **Resource Management**: Track critical system resources such as **CPU, RAM, GPU, and VRAM** to ensure optimal model performance.
- ğŸ”¹ **Model Control**: Start, stop, and manage models via simple CLI commands.
- ğŸ”¹ **Interactive Interface**: Navigate through an intuitive TUI powered by **Rich** and **Textual** libraries.

---

## ğŸ“Œ Features

ğŸ– **Monitor Running AI Models**: Get an overview of all active models, their configurations, and resource usage.

ğŸ– **Track System Resource Usage**: Keep tabs on CPU, RAM, GPU, and VRAM in real time.

ğŸ– **Start & Stop Models via CLI**: Manage the lifecycle of your AI models effortlessly from the terminal.

ğŸ– **TUI-Based Interactive Interface**: Utilize a clean, responsive UI for managing models with minimal effort.

ğŸ– **Performance Metrics**: View detailed performance stats including throughput, latency, and memory usage.

ğŸ– **Live Log Monitoring**: Inspect logs in real-time to debug and monitor model behaviors.

---

## ğŸ“Œ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/lazyllms.git
cd lazyllms
```

### **2ï¸âƒ£ Set Up Virtual Environment**
```bash
python -m venv lazyllms_venv
source lazyllms_venv/bin/activate   # For macOS/Linux
lazyllms_venv\Scripts\activate      # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Usage Guide

### ğŸ” **List Running Models**
```bash
python main.py list
```
ğŸ”¹ This will show **all currently running AI models** with their details and resource usage.

---

### ğŸ“Š **Launch the Terminal UI**
```bash
python main.py tui
```
ğŸ”¹ **Key Features in TUI:**
- âœ”ï¸ **Displays running models in a table with detailed stats**
- âœ”ï¸ **Shows system resource usage (CPU, RAM, GPU, VRAM)**
- âœ”ï¸ **Press `r` to refresh data.**
- âœ”ï¸ **Press `q` to quit the TUI.**
- âœ”ï¸ **Press `l` to toggle live logs.**

---

## ğŸ“Œ Screenshots

### ğŸ“Š **Model & System Usage View**
![LazyLLMs UI](https://raw.githubusercontent.com/iscloudready/lazyllms/refs/heads/main/Images/home.png)

This view provides a comprehensive display of:
- ğŸ”¹ **Available Models**: Name, parameters, size, type, and status.
- ğŸ”¹ **System Resources**: CPU, RAM, GPU, VRAM usage in real time.
- ğŸ”¹ **Performance Stats**: Throughput, latency, and memory usage for each model.
- ğŸ”¹ **Model Details & Live Logs**: Detailed view of selected model attributes and real-time logs.

---

## ğŸ—ï¸ Roadmap - Future Enhancements

ğŸš€ **Auto-refreshing UI**: Enable real-time updates without the need for manual refresh.

ğŸ”¥ **Live Log Monitoring**: Advanced logging features with filtering and search capabilities.

ğŸ“¦ **Docker & Kubernetes Support**: Seamless monitoring of AI models running inside containerized environments.

âš¡ **GPU Load Optimization**: Enhanced tracking of GPU-specific metrics and performance tuning.

---

## ğŸ¤ Contributing

We welcome contributions from the community! Follow these simple steps to contribute:

1ï¸âƒ£ **Fork** the repository.

2ï¸âƒ£ **Create a Feature Branch**:
```bash
git checkout -b feature-xyz
```

3ï¸âƒ£ **Commit Your Changes**:
```bash
git commit -m "Added feature xyz"
```

4ï¸âƒ£ **Push to Your Fork**:
```bash
git push origin feature-xyz
```

5ï¸âƒ£ **Submit a Pull Request** ğŸš€

---

## ğŸ“ License

This project is **MIT Licensed**. See the [LICENSE](LICENSE) file for more details.

---

## ğŸ“¨ Connect with Us

ğŸ“§ **Email**: email@example.com

---

Thank you for using **LazyLLMs**! ğŸš€ Feel free to share your feedback and contributions!

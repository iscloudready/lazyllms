# ğŸ¦¾ LazyLLMs - Lightweight LLM Model Manager

[![GitHub License](https://img.shields.io/github/license/your-repo/lazyllms)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/)
[![Contributors](https://img.shields.io/github/contributors/your-repo/lazyllms)](https://github.com/your-repo/lazyllms/graphs/contributors)

---

## ğŸš€ Overview

**LazyLLMs** is a **TUI-based (Terminal UI) Model Manager**, inspired by **LazyDocker**, for monitoring and managing AI models like **Ollama models**. It provides a **real-time system resource view** and **control over running models** directly from the command line.

### ğŸ”¹ Features:
âœ… **Monitor Running AI Models**
âœ… **Track System Resource Usage (CPU, RAM, GPU, VRAM)**
âœ… **Start & Stop Models via CLI**
âœ… **TUI-Based Interactive Interface (Rich & Textual)**

---

## ğŸ“Œ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-repo/lazyllms.git
cd lazyllms
```

### **2ï¸âƒ£ Set Up Virtual Environment**
```bash
python -m venv lazyllms_venv
source lazyllms_venv/bin/activate   # For macOS/Linux
lazyllms_venv\Scripts\activate      # For Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Usage Guide

### ğŸ” **List Running Models**
```bash
python main.py list
```
ğŸ”¹ This will show **all currently running AI models**.

---

### ğŸ“Š **Launch the Terminal UI**
```bash
python main.py tui
```
âœ”ï¸ **Displays running models in a table**
âœ”ï¸ **Shows system resource usage (CPU, RAM, GPU, VRAM)**
âœ”ï¸ **Press `r` to refresh data.**
âœ”ï¸ **Press `q` to quit the TUI.**

---

## ğŸ“Œ Screenshots

### **ğŸ“Š Model & System Usage View**
![LazyLLMs UI](https://raw.githubusercontent.com/iscloudready/lazyllms/refs/heads/main/Images/home.png)

---

## ğŸ—ï¸ Roadmap - Future Enhancements

ğŸš€ **Auto-refreshing UI** (Real-time updates without manual refresh)
ğŸ”¥ **Live Log Monitoring** (Display logs of running models)
ğŸ“¦ **Docker & Kubernetes Support** (Monitor AI models inside containers)
âš¡ **GPU Load Optimization** (Track GPU-specific metrics)

---

## ğŸ¤ Contributing

We welcome contributions! Follow these steps:

1ï¸âƒ£ **Fork** the repo
2ï¸âƒ£ **Create a Feature Branch** (`feature-xyz`)
3ï¸âƒ£ **Commit Changes** (`git commit -m "Added feature xyz"`)
4ï¸âƒ£ **Submit a Pull Request** ğŸš€

---

## ğŸ“ License

This project is **MIT Licensed**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ’Œ Connect with Us

ğŸ“§ **Email**: your-email@example.com
ğŸ¦ **Twitter**: [@your-handle](https://twitter.com/)
ğŸŒŸ **LinkedIn**: [Your Profile](https://linkedin.com/in/)

